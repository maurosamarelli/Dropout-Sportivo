{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2750, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = pd.read_csv(\"04 important_features.csv\")\n",
    "dropout.drop(\"Unnamed: 0\", 1, inplace=True)\n",
    "dropout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grado_divertimento_allenamento</th>\n",
       "      <th>personalita_competitiva</th>\n",
       "      <th>agonismo</th>\n",
       "      <th>sport_passione</th>\n",
       "      <th>grado_conciliare_scuola_sport</th>\n",
       "      <th>sesso_maschio</th>\n",
       "      <th>calcio</th>\n",
       "      <th>sesso_femmina</th>\n",
       "      <th>personalita_tranquilla</th>\n",
       "      <th>divertimento</th>\n",
       "      <th>...</th>\n",
       "      <th>maschio_calcio</th>\n",
       "      <th>personalita_polemica</th>\n",
       "      <th>sport_agonistico_genitori</th>\n",
       "      <th>tipo_sport_significativo_squadra</th>\n",
       "      <th>frequenza_settimanale</th>\n",
       "      <th>tipo_sport_significativo_individuale</th>\n",
       "      <th>sport_bisogno_corpo_mente</th>\n",
       "      <th>personalita_aperta</th>\n",
       "      <th>femmina_pallavolo_nuoto</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grado_divertimento_allenamento  personalita_competitiva  agonismo  \\\n",
       "0                               3                        4         1   \n",
       "1                               3                        4         1   \n",
       "2                               3                        5         1   \n",
       "3                               0                        6         1   \n",
       "4                               2                        2         0   \n",
       "\n",
       "   sport_passione  grado_conciliare_scuola_sport  sesso_maschio  calcio  \\\n",
       "0               1                              3              1       1   \n",
       "1               0                              3              0       0   \n",
       "2               0                              4              1       1   \n",
       "3               1                              2              1       1   \n",
       "4               0                              2              1       1   \n",
       "\n",
       "   sesso_femmina  personalita_tranquilla  divertimento  ...  maschio_calcio  \\\n",
       "0              0                       4             0  ...               0   \n",
       "1              1                       6             0  ...               0   \n",
       "2              0                       3             1  ...               1   \n",
       "3              0                       0             0  ...               0   \n",
       "4              0                       5             1  ...               1   \n",
       "\n",
       "   personalita_polemica  sport_agonistico_genitori  \\\n",
       "0                     1                          0   \n",
       "1                     1                          0   \n",
       "2                     3                          0   \n",
       "3                     6                          0   \n",
       "4                     4                          0   \n",
       "\n",
       "   tipo_sport_significativo_squadra  frequenza_settimanale  \\\n",
       "0                                 0                      3   \n",
       "1                                 0                      2   \n",
       "2                                 1                      3   \n",
       "3                                 1                      3   \n",
       "4                                 1                      3   \n",
       "\n",
       "   tipo_sport_significativo_individuale  sport_bisogno_corpo_mente  \\\n",
       "0                                     1                          0   \n",
       "1                                     1                          0   \n",
       "2                                     0                          0   \n",
       "3                                     0                          0   \n",
       "4                                     0                          0   \n",
       "\n",
       "   personalita_aperta  femmina_pallavolo_nuoto  dropout  \n",
       "0                   5                        0        1  \n",
       "1                   5                        0        1  \n",
       "2                   5                        0        1  \n",
       "3                   6                        0        0  \n",
       "4                   5                        0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2750, 21), (2750,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dropout.drop(\"dropout\", 1)\n",
    "y = dropout.dropout\n",
    "models = dict()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1'}\n",
      "   mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \\\n",
      "0                0.69                 0.69              0.72          0.71   \n",
      "\n",
      "   mean_test_roc_auc  \n",
      "0               0.75  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models['LogisticRegression FS'] = dict()\n",
    "#params = {'C':[0.01, 0.1, 1, 10, 100], 'penalty':[\"l1\", \"l2\"]}\n",
    "params = {'C':[0.1], 'penalty':[\"l1\"]}\n",
    "clf = GridSearchCV(LogisticRegression(random_state=0), params, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "                  refit=\"recall\").fit(X, y)\n",
    "models['LogisticRegression FS']['model'] = clf.best_estimator_\n",
    "models['LogisticRegression FS']['params'] = clf.best_params_\n",
    "models['LogisticRegression FS']['metrics'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"mean_test\"), 2)\n",
    "models['LogisticRegression FS']['cv_results'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"test\").filter(like=\"split\"), 2)\n",
    "print(models['LogisticRegression FS']['params'])\n",
    "print(models['LogisticRegression FS']['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grado_divertimento_allenamento</th>\n",
       "      <th>personalita_competitiva</th>\n",
       "      <th>agonismo</th>\n",
       "      <th>prob_dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grado_divertimento_allenamento  personalita_competitiva  agonismo  \\\n",
       "0                               0                        0         0   \n",
       "1                               0                        0         1   \n",
       "2                               0                        1         0   \n",
       "3                               0                        1         1   \n",
       "4                               0                        2         0   \n",
       "\n",
       "   prob_dropout  \n",
       "0          0.91  \n",
       "1          0.83  \n",
       "2          0.89  \n",
       "3          0.80  \n",
       "4          0.88  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = pd.DataFrame({'grado_divertimento_allenamento':X.grado_divertimento_allenamento, \n",
    "                   'personalita_competitiva':X.personalita_competitiva,\n",
    "                   'agonismo':X.agonismo})\n",
    "clf = LogisticRegression(random_state=0).fit(mod, y)\n",
    "x1, x2, x3 = [], [], []\n",
    "for gda in range(5):\n",
    "    for pc in range(7):\n",
    "        for ag in range(2):\n",
    "            x1.append(gda)\n",
    "            x2.append(pc)\n",
    "            x3.append(ag)\n",
    "df = pd.DataFrame({'grado_divertimento_allenamento':pd.Series(x1),\n",
    "                 'personalita_competitiva':pd.Series(x2),\n",
    "                 'agonismo':pd.Series(x3)})\n",
    "df['prob_dropout'] = round(pd.DataFrame(clf.predict_proba(df)).iloc[:, 1], 2)\n",
    "df.head()\n",
    "#df.to_csv(\"LR model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 0.05, 'n_estimators': 500}\n",
      "   mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \\\n",
      "0                0.67                 0.66              0.71          0.69   \n",
      "\n",
      "   mean_test_roc_auc  \n",
      "0               0.75  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models['RandomForest FS'] = dict()\n",
    "params = {'criterion':['gini'], 'max_depth':[3], 'min_samples_leaf':[0.05], 'n_estimators':[500], 'bootstrap':[False]}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=0), params, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "                  refit='recall').fit(X, y)\n",
    "models['RandomForest FS']['model'] = clf.best_estimator_\n",
    "models['RandomForest FS']['params'] = clf.best_params_\n",
    "models['RandomForest FS']['metrics'] = round(pd.DataFrame(clf.cv_results_).query('rank_test_recall == 1').filter(like=\"mean_test\"), 2)\n",
    "models['RandomForest FS']['cv_results'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"test\").filter(like=\"split\"), 2)\n",
    "print(models['RandomForest FS']['params'])\n",
    "print(models['RandomForest FS']['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'kernel': 'poly'}\n",
      "   mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \\\n",
      "0                0.68                 0.66              0.79          0.72   \n",
      "\n",
      "   mean_test_roc_auc  \n",
      "0               0.75  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "models['SVM FS'] = dict()\n",
    "#params = {'C':[0.1, 1, 10], 'kernel':[\"linear\", \"poly\", \"rbf\"]}\n",
    "params = {'C':[0.1], 'kernel':[\"poly\"]}\n",
    "clf = GridSearchCV(SVC(random_state=0, probability=True), params, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "                  refit=\"recall\").fit(X, y)\n",
    "models['SVM FS']['model'] = clf.best_estimator_\n",
    "models['SVM FS']['params'] = clf.best_params_\n",
    "models['SVM FS']['metrics'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"mean_test\"), 2)\n",
    "models['SVM FS']['cv_results'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"test\").filter(like=\"split\"), 2)\n",
    "print(models['SVM FS']['params'])\n",
    "print(models['SVM FS']['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 50, 'p': 2, 'weights': 'distance'}\n",
      "   mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \\\n",
      "0                0.68                 0.67              0.72           0.7   \n",
      "\n",
      "   mean_test_roc_auc  \n",
      "0               0.75  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models['KNN FS'] = dict()\n",
    "#params = {'n_neighbors':[50, 100, 200], 'p':[1, 2], 'weights':['uniform', 'distance']}\n",
    "params = {'n_neighbors':[50], 'p':[2], 'weights':['distance']}\n",
    "clf = GridSearchCV(KNeighborsClassifier(), params, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "                  refit=\"recall\").fit(X, y)\n",
    "models['KNN FS']['model'] = clf.best_estimator_\n",
    "models['KNN FS']['params'] = clf.best_params_\n",
    "models['KNN FS']['metrics'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"mean_test\"), 2)\n",
    "models['KNN FS']['cv_results'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"test\").filter(like=\"split\"), 2)\n",
    "print(models['KNN FS']['params'])\n",
    "print(models['KNN FS']['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "   mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \\\n",
      "0                0.69                 0.67              0.77          0.72   \n",
      "\n",
      "   mean_test_roc_auc  \n",
      "0               0.76  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "models['MLP FS'] = dict()\n",
    "#params = {'hidden_layer_sizes':[(50, ), (100, ), (150, )], 'activation':['tanh', 'relu']}\n",
    "params = {'hidden_layer_sizes':[(100, )], 'activation':['tanh']}\n",
    "clf = GridSearchCV(MLPClassifier(random_state=0), params, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "                  refit=\"recall\").fit(X, y)\n",
    "models['MLP FS']['model'] = clf.best_estimator_\n",
    "models['MLP FS']['params'] = clf.best_params_\n",
    "models['MLP FS']['metrics'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"mean_test\"), 2)\n",
    "models['MLP FS']['cv_results'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"test\").filter(like=\"split\"), 2)\n",
    "print(models['MLP FS']['params'])\n",
    "print(models['MLP FS']['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \\\n",
      "0                 0.7                 0.68              0.76          0.72   \n",
      "\n",
      "   mean_test_roc_auc  \n",
      "0               0.77  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "models['VotingSoft FS'] = dict()\n",
    "clf = GridSearchCV(VotingClassifier(estimators=[('lr', models['LogisticRegression FS']['model']),\n",
    "                                                ('rf', models['RandomForest FS']['model']),\n",
    "                                                ('svm', models['SVM FS']['model']),\n",
    "                                                ('knn', models['KNN FS']['model']),\n",
    "                                                ('mlp', models['MLP FS']['model'])], voting=\"soft\"), {}, cv=10, \n",
    "                   scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], refit=\"recall\").fit(X, y)\n",
    "models['VotingSoft FS']['model'] = clf.best_estimator_\n",
    "models['VotingSoft FS']['params'] = clf.best_params_\n",
    "models['VotingSoft FS']['metrics'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"mean_test\"), 2)\n",
    "models['VotingSoft FS']['cv_results'] = round(pd.DataFrame(clf.cv_results_).query(\"rank_test_recall == 1\").filter(like=\"test\").filter(like=\"split\"), 2)\n",
    "print(models['VotingSoft FS']['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(models['LogisticRegression FS'], open('LogisticRegression FS', 'wb'))\n",
    "pickle.dump(models['RandomForest FS'], open('RandomForest FS', 'wb'))\n",
    "pickle.dump(models['SVM FS'], open('SVM FS', 'wb'))\n",
    "pickle.dump(models['KNN FS'], open('KNN FS', 'wb'))\n",
    "pickle.dump(models['MLP FS'], open('MLP FS', 'wb'))\n",
    "pickle.dump(models['VotingSoft FS'], open('VotingSoft FS', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
